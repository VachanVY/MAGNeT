{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.utils.audio_utils import playAudio\n",
    "from src.model import get_magnet_model, MAGNET\n",
    "from src.preprocess_ops import PreProOps\n",
    "from src.music_bench import (\n",
    "    MAX_SEC, split_ds,\n",
    "    shuffle_preserve_order,\n",
    "    QCODING_LEN,\n",
    ")\n",
    "from train import MagnetTrainer\n",
    "from src.utils.lr_scheduler import CosineDecayWithWarmup\n",
    "from src.music_bench import AUDIO_TXT_PATH, ioPathTextDs, PreProDataset\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "from train import tonfig\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = (\n",
    "        torch.autocast(\n",
    "                device_type=\"cuda\" if \"cuda\" in DEVICE.type else \"cpu\",\n",
    "                dtype={\"bfloat16\": torch.bfloat16,\n",
    "                       \"float16\" : torch.float16, \"float32\": torch.float32}[\"float32\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvy/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Parameters in Encodec Model: 14.85181 Million Parameters\n",
      "\n",
      "\n",
      "Number of Parameters in T5 Model (google-t5/t5-small): 35.330816 Million Parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_ops = PreProOps(\n",
    "    max_sec=QCODING_LEN,\n",
    "    print_info=True,\n",
    "    device=DEVICE.type,\n",
    "    compile=False,\n",
    "    autocast=ctx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "iterator = lambda X, y, split: iter(\n",
    "        PreProDataset(\n",
    "            split=split,\n",
    "            randgen=r.Random(tonfig.seed),\n",
    "            audio_pad_id=tonfig.mask_id,\n",
    "            qcoding_len=tonfig.seqlen,\n",
    "            device=DEVICE.type,\n",
    "            pre_computed_tensors_dirpath=tonfig.PRECOMPUTED_TENSORS_DIRPATH,\n",
    "            online=True,\n",
    "            wav_paths=X, texts=y,\n",
    "            preprocess_ops=preprocess_ops,\n",
    "        ).iter_batches()\n",
    "    )\n",
    "\n",
    "paths, texts = ioPathTextDs(\n",
    "    save_path=AUDIO_TXT_PATH,\n",
    "    batch_size=64,\n",
    "    split_float=0.9,\n",
    "    return_ds=True\n",
    ")\n",
    "train_iterator = iterator(paths, texts, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnet_model:MAGNET = get_magnet_model(compile=False).to(DEVICE)\n",
    "debug_input = next(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Overfitting lil batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 4, 750]), torch.Size([64, 196, 512]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_input[0][\"qcode\"].shape, debug_input[1].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_input = ({\"qcode\": debug_input[0][\"qcode\"][:2].to(DEVICE), \"mask\": debug_input[0][\"mask\"][:2].to(DEVICE)}\n",
    "               , debug_input[1][:2].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 750]), torch.Size([2, 196, 512]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_input[0][\"qcode\"].shape, debug_input[1].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.833728 Million Parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in magnet_model.parameters() if p.requires_grad)/1e6, \"Million Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnet_trainer = MagnetTrainer(\n",
    "    magnet_model=magnet_model,\n",
    "    config=tonfig\n",
    ")\n",
    "\n",
    "get_lr = CosineDecayWithWarmup(\n",
    "    warmup_steps=tonfig.warmup_steps,\n",
    "    max_learning_rate=tonfig.max_learning_rate,\n",
    "    decay_steps=tonfig.decay_steps,\n",
    "    min_learning_rate=tonfig.min_learning_rate\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(tonfig.dtype==\"float16\"))\n",
    "\n",
    "optimizer = magnet_model.configure_optimizers(\n",
    "    weight_decay=tonfig.weight_decay,\n",
    "    learning_rate=5e-4,\n",
    "    betas=(tonfig.beta1, tonfig.beta2),\n",
    "    device_type=\"cuda\" if \"cuda\" in DEVICE.type else \"cpu\"\n",
    ")\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_ema(ema_model:MAGNET, model:MAGNET, decay:float):\n",
    "    ema_params = OrderedDict(ema_model.named_parameters())\n",
    "    model_params = OrderedDict(model.named_parameters())\n",
    "\n",
    "    for name, param in model_params.items():\n",
    "        # ema = decay*ema + (1-decay)*no_ema\n",
    "        ema_params[name].mul_(decay).add_(param.data, alpha=1-decay)\n",
    "\n",
    "def requires_grad(model:nn.Module, requires_grad:bool):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = deepcopy(magnet_model).to(DEVICE) # sampling with ema model\n",
    "requires_grad(ema, requires_grad=False)\n",
    "magnet_model.train()\n",
    "ema.eval()\n",
    "update_ema(ema, magnet_model, decay=0.0) # ema_model weights are in sync with magnet_model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cl:\n",
    "    def iterrr():\n",
    "        yield {\"qcode\": debug_input[0][\"qcode\"].to(DEVICE), \"mask\": debug_input[0][\"mask\"].to(DEVICE)}, debug_input[1].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training about to start...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 512 n 1500 k 512 mat1_ld 512 mat2_ld 512 result_ld 512 abcType 0 computeType 77 scaleType 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m             losses\u001b[38;5;241m.\u001b[39mappend(lossf); accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses, accuracies\n\u001b[0;32m---> 57\u001b[0m losses, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtest_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Clear Output\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mtest_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tonfig\u001b[38;5;241m.\u001b[39mnum_grad_accumalation_steps):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 16\u001b[0m         loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmagnet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmini_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43maudio_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_text\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m tonfig\u001b[38;5;241m.\u001b[39mnum_grad_accumalation_steps\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# async prefetch immediately\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/train.py:247\u001b[0m, in \u001b[0;36mMagnetTrainer.mini_train_step\u001b[0;34m(self, audio_input, cond_tensor)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# use final_mask on audio tokens\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# where final_mask is True, replace with mask_id else audio_tokens\u001b[39;00m\n\u001b[1;32m    245\u001b[0m model_input_audio_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(final_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_id, audio_tokens) \u001b[38;5;66;03m# (B, Nq, T)\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m logits:Tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmagnet_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input_audio_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_tensor\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, Nq, T, cardinality)\u001b[39;00m\n\u001b[1;32m    252\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_magnet_cross_entropy(\n\u001b[1;32m    253\u001b[0m     y_true\u001b[38;5;241m=\u001b[39maudio_tokens, y_pred\u001b[38;5;241m=\u001b[39mlogits,\n\u001b[1;32m    254\u001b[0m     loss_mask\u001b[38;5;241m=\u001b[39mloss_mask, phase\u001b[38;5;241m=\u001b[39mphase\n\u001b[1;32m    255\u001b[0m )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# (B, Nq, T) =sum(-1, -2)> (B,) =mean=> ()\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/src/model.py:226\u001b[0m, in \u001b[0;36mMAGNET.forward\u001b[0;34m(self, x, conditioning_tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# emb: sum((cardinality {in dimension T}, d_model) ==x[:, codebook]:=(B, T)=> (B, T, d_model)s)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[codebook](x[:, codebook]) \u001b[38;5;28;01mfor\u001b[39;00m codebook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnq)]) \u001b[38;5;66;03m# (B, T, d_model)\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestricted_att_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, seq_mask, cross_att_mask) # (B, T, d_model)\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# stack((B, T, cardinality), dim=1) => (B, nq, T, cardinality)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinears[codebook](x) \u001b[38;5;28;01mfor\u001b[39;00m codebook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnq)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/src/model.py:171\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, xrc, conditioning_tensor, xrc_att_mask)\u001b[0m\n\u001b[1;32m    169\u001b[0m xrc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emebddings\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 171\u001b[0m     xrc \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxrc_att_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     xrc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm(xrc)\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/src/model.py:140\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[0;34m(self, xrc, conditioning_tensor, xrc_att_mask)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Second SubBlock\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conditioning_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     xrc \u001b[38;5;241m=\u001b[39m xrc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioning_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# (B, T, d_model)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Third SubBlock\u001b[39;00m\n\u001b[1;32m    143\u001b[0m xrc \u001b[38;5;241m=\u001b[39m xrc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(xrc)) \u001b[38;5;66;03m# (B, T, d_model)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/src/model.py:84\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, q, k, v, attn_mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m,     \u001b[38;5;66;03m# CROSS ATTN       SELF ATTN\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     q:Tensor, \u001b[38;5;66;03m# (B, T, d_model); (B, T, d_model)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# (T, T) A float mask of the same type as query, key, value that is added to the attention score.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m ):\n\u001b[1;32m     83\u001b[0m     T, N \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwk(k), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv(v) \u001b[38;5;66;03m# (B, T, d_model), (B, N, d_model), (B, N, d_model)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, T, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# (B, num_heads, T, hdim)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# (B, num_heads, N, hdim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/MAGNeT/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 512 n 1500 k 512 mat1_ld 512 mat2_ld 512 result_ld 512 abcType 0 computeType 77 scaleType 0"
     ]
    }
   ],
   "source": [
    "losses, accuracies = [], []\n",
    "def test_train():\n",
    "    audio_input, cond_text = debug_input\n",
    "\n",
    "    print(\"Training about to start...\")\n",
    "    t0 = time.time()\n",
    "    for step in range(0, 2000):\n",
    "        # set learning rate for all params\n",
    "        lr = 5e-4\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        # gradient accumulation step\n",
    "        for mini_step in range(tonfig.num_grad_accumalation_steps):\n",
    "            with ctx:\n",
    "                loss, accuracy = magnet_trainer.mini_train_step(\n",
    "                    audio_input=audio_input, cond_tensor=cond_text\n",
    "                )\n",
    "                loss /= tonfig.num_grad_accumalation_steps\n",
    "                # async prefetch immediately\n",
    "                audio_input, cond_text = debug_input\n",
    "\n",
    "            # keeps on scaling and adrequires_gradrd()\n",
    "\n",
    "        if tonfig.clipnorm is not None:\n",
    "            # unscale the gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # clips gradients in-place to grad norm\n",
    "            grad_norm = nn.utils.clip_grad_norm_(magnet_model.parameters(), max_norm=tonfig.clipnorm)\n",
    "\n",
    "        # calls unscale to the optimizer unless already called, checks for infs and nans as a part of unscale_\n",
    "        # calls optimizer.step on unscaled grads if no infs and nans else optimizer.step is skipped\n",
    "        scaler.step(optimizer)\n",
    "        # Update the scale factor\n",
    "        scaler.update()\n",
    "\n",
    "        # flush grads to save memory\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # update ema model\n",
    "        update_ema(ema, magnet_model, decay=tonfig.ema_momentum)\n",
    "\n",
    "        # some logging\n",
    "        t1 = time.time()\n",
    "        dt = t1-t0\n",
    "        t0 = t1\n",
    "        if step % tonfig.log_interval == 0:\n",
    "            # multiply as loss was scaled for gradient accumulation\n",
    "            lossf = loss.item() * tonfig.num_grad_accumalation_steps\n",
    "            print(\n",
    "                f\"| Step: {step} || Loss: {lossf:.4f} || Masked Accuracy: {accuracy[1]:.4f} | Accuracy: {accuracy[0]:.4f} |\"\n",
    "                f\"| LR: {lr:e} || dt: {dt*1000:.2f}ms || Norm: {grad_norm} ||\"\n",
    "            )\n",
    "            losses.append(lossf); accuracies.append(accuracy)\n",
    "    return losses, accuracies\n",
    "\n",
    "losses, accuracies = test_train() # Clear Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(accuracies, label=\"Accuracy \\ Masked Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(losses), max(accuracies), losses.index(min(losses)), accuracies.index(max(accuracies)), losses[1000:].index(max(losses[1000:]))+1000, max(losses[1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_input = next(train_iterator)\n",
    "debug_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnet_model.eval()\n",
    "gen_tok = magnet_model.generate(\n",
    "    prompt=debug_input[1],\n",
    "    preprocess_ops=preprocess_ops,\n",
    "    device=DEVICE,\n",
    "    top_p=0.9,\n",
    "    decoding_steps=[20, 10, 10, 10]\n",
    ") # (2, 4, 750)\n",
    "gen_wav = preprocess_ops.getAudioFromCodings(gen_tok) # (2, 1, 240000)\n",
    "playAudio(tensor=gen_wav[0].squeeze())\n",
    "playAudio(tensor=gen_wav[1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema.eval()\n",
    "gen_tok = ema.generate(\n",
    "    prompt=debug_input[1],\n",
    "    preprocess_ops=preprocess_ops,\n",
    "    device=DEVICE,\n",
    "    top_p=0.9,\n",
    "    decoding_steps=[20, 10, 10, 10]\n",
    ")\n",
    "gen_wav = preprocess_ops.getAudioFromCodings(gen_tok)\n",
    "playAudio(tensor=gen_wav[0].squeeze())\n",
    "playAudio(tensor=gen_wav[1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original, from dataset\n",
    "gen_tok = debug_input[0][\"qcode\"][1][None]\n",
    "gen_wav = preprocess_ops.getAudioFromCodings(gen_tok)\n",
    "playAudio(tensor=gen_wav[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nothing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(num_decoding_steps):\n",
    "    func = lambda t: math.cos((math.pi * t)/(2*num_decoding_steps))\n",
    "    plt.plot(list(range(num_decoding_steps)), [func(t) for t in range(num_decoding_steps)], label=\"mask_p\")\n",
    "    plt.xlabel(\"Decoding Steps\")\n",
    "    plt.ylabel(\"Mask Probability (in inference)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing as tp\n",
    "import glob\n",
    "import os\n",
    "import random as r\n",
    "\n",
    "class PreProDataset:\n",
    "    def __init__(\n",
    "        self, *,\n",
    "        split:str, # 'train' or 'val'\n",
    "        audio_pad_id:int,\n",
    "        qcoding_len:int,\n",
    "        device:str,\n",
    "        randgen:r.Random,\n",
    "        pre_computed_tensors_dirpath:tp.Optional[str]=None,\n",
    "        online:bool=False,\n",
    "        # Optionally None if online is False\n",
    "        wav_paths:tp.Optional[list[str]]=None,\n",
    "        texts:tp.Optional[list[str]]=None,\n",
    "        preprocess_ops:tp.Optional[tp.Any]=None\n",
    "    ):\n",
    "        assert split in [\"train\", \"val\"]\n",
    "        self.online = online\n",
    "\n",
    "        if self.online:\n",
    "            assert all([wav_paths is not None, texts is not None, preprocess_ops is not None])\n",
    "            self.wav_paths = wav_paths # (N//B, B)\n",
    "            self.texts = texts # (N//B, B)\n",
    "            self.preprocess_ops = preprocess_ops\n",
    "\n",
    "            self.wav_paths, self.texts = split_ds(self.wav_paths, self.texts, split_float=0.9)[split]\n",
    "        else:\n",
    "            assert pre_computed_tensors_dirpath is not None\n",
    "            shard_filenames = sorted(glob.glob(os.path.join(pre_computed_tensors_dirpath, \"musicbench*.pt\")))\n",
    "            assert len(shard_filenames) > 0\n",
    "            self.shard_filenames = split_ds(shard_filenames, None, split_float=0.9)[split]\n",
    "\n",
    "        self.audio_pad_id = audio_pad_id\n",
    "        self.qcoding_len = qcoding_len\n",
    "        self.randgen = randgen\n",
    "        self.device = torch.device(device)\n",
    "    \n",
    "    def iter_batches(self):\n",
    "        while True:\n",
    "            if self.online:\n",
    "                self.wav_paths, self.texts = shuffle_preserve_order(self.wav_paths, self.texts, randgen=self.randgen)\n",
    "                for batched_wavpath, batched_text_str in zip(self.wav_paths, self.texts):\n",
    "                    qcodings = self.preprocess_ops.get_qcodings(\n",
    "                        batched_wavpath, qcoding_len=self.qcoding_len\n",
    "                    )\n",
    "                    cond_tensor = self.preprocess_ops.get_cond_tensor(batched_text_str)\n",
    "                    yield qcodings, cond_tensor\n",
    "            else:\n",
    "                self.randgen.shuffle(self.shard_filenames)\n",
    "                for shard_filename in self.shard_filenames:\n",
    "                    qcodings, cond_tensor = torch.load(shard_filename)\n",
    "                    yield qcodings, cond_tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
